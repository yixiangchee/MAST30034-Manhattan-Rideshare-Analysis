{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAST30034 Applied Data Science Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor, LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1-3\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.executor.memory\", \"10g\")\n",
    "    .config(\"spark.driver.memory\", \"10g\")\n",
    "    .config(\"spark.sql.session.timeZone\",  \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = spark \\\n",
    "            .read.parquet('../data/curated/modelling/model_data')\n",
    "model_test_data = spark \\\n",
    "            .read.parquet('../data/curated/modelling/model_test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble and One-Hot Encode Features for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to be one-hot encoded\n",
    "CATEGORICAL_LIST = [\"month\", \"day\", \"day_of_week\", \"hour\",\n",
    "                    'PULocationID', \"hvfhs_license_num\"]\n",
    "\n",
    "stage_list = []\n",
    "encoded_cols = []\n",
    "\n",
    "# Maps features into indices\n",
    "for feature in CATEGORICAL_LIST:\n",
    "    stage_list.append(StringIndexer(inputCol=feature,\n",
    "                                    outputCol=f\"{feature}_index\"))\n",
    "\n",
    "# Perform one-hot encoding\n",
    "for feature in CATEGORICAL_LIST:\n",
    "    stage_list.append(OneHotEncoder(inputCol=f\"{feature}_index\",\n",
    "                                    outputCol=f\"{feature}_vec\"))\n",
    "    encoded_cols.append(f\"{feature}_vec\")\n",
    "\n",
    "# Create pipeline and pass all stages\n",
    "encoding_pipeline = Pipeline(stages=stage_list)\n",
    "sdf_transformed = encoding_pipeline.fit(model_data).transform(model_data)\n",
    "sdf_test_transformed = encoding_pipeline \\\n",
    "                        .fit(model_data).transform(model_test_data)\n",
    "(train_data, test_data) = sdf_transformed, sdf_test_transformed\n",
    "\n",
    "feature_list = encoded_cols + [\"rent\"]\n",
    "assembler = VectorAssembler(inputCols=feature_list, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model and Generate Predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    labelCol=\"total_pickups\",\n",
    "    featuresCol=\"features\",\n",
    "    seed=0,\n",
    "    numTrees=20)\n",
    "pipeline_rf = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# Train model\n",
    "model_rf = pipeline_rf.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions_rf = model_rf.transform(test_data)\n",
    "\n",
    "# Select example rows to display\n",
    "predictions_rf.select(\"prediction\", \"total_pickups\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary Least Squares (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol=\"total_pickups\", featuresCol=\"features\")\n",
    "pipeline_lm = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# Train model\n",
    "model_lm = pipeline_lm.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions_lm = model_lm.transform(test_data)\n",
    "\n",
    "# Select example rows to display\n",
    "predictions_lm.select(\"prediction\", \"total_pickups\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for OLS Output from: https://stackoverflow.com/questions/42935914/how-to-map-features-from-the-output-of-a-vectorassembler-back-to-the-column-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_pickups\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Summary for OLS\n",
    "rmse_lm = evaluator.evaluate(predictions_lm)\n",
    "print(\"RMSE (OLS) on test data = %g\" % rmse_lm)\n",
    "lm = model_lm.stages[1]  # get lm model from pipeline\n",
    "print(lm)\n",
    "print(f\"Adjusted R^2 for OLS: {lm.summary.r2adj}\")\n",
    "\n",
    "# Get name of features\n",
    "attrs = sorted(\n",
    "    (attr[\"idx\"], attr[\"name\"]) for attr in (chain(*predictions_lm\n",
    "                                                   .schema[lm.summary\n",
    "                                                             .featuresCol]\n",
    "                                                   .metadata[\"ml_attr\"]\n",
    "                                                   [\"attrs\"].values())))\n",
    "\n",
    "# Get OLS Output\n",
    "lm_output = pd.DataFrame(\n",
    "    data=[(name, lm.coefficients[idx],\n",
    "          lm.summary.coefficientStandardErrors[idx],\n",
    "          lm.summary.tValues[idx], lm.summary.pValues[idx])\n",
    "          for idx, name in attrs],\n",
    "    columns=[\"Feature\", \"Coefficient\", \"Standard Error\", \"t-value\", \"p-value\"]\n",
    ")\n",
    "print(\"Last 5 Coefficients for Features: \")\n",
    "print(lm_output.tail())\n",
    "\n",
    "# Summary for Random Forest\n",
    "rmse_rf = evaluator.evaluate(predictions_rf)\n",
    "print(\"RMSE (Random Forest) on test data = %g\" % rmse_rf)\n",
    "rf = model_rf.stages[1]  # get rf model from pipeline\n",
    "print(model_rf.stages[1])\n",
    "\n",
    "# Get Random Forest Feature Importances\n",
    "rf_output = pd.DataFrame(\n",
    "    data=[(name, rf.featureImportances[idx]) for idx, name in attrs],\n",
    "    columns=[\"Feature\", \"Feature Importance\"]\n",
    ")\n",
    "rf_output.sort_values(by=\"Feature Importance\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis (Uber's Hourly Pickup, 15th April 2022, Upper West Side North)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns of predictiond data we want to extract\n",
    "EXTRACT_COLS = [\"month\", \"day\", \"hour\", \"PULocationID\", \"hvfhs_license_num\",\n",
    "                \"total_pickups\", \"prediction\"]\n",
    "\n",
    "# Extract predictions from OLS\n",
    "pred_sample_lm = predictions_lm.where(\n",
    "    (F.col(\"month\") == 4)\n",
    "    & (F.col(\"day\") == 15)\n",
    "    & (F.col(\"PULocationID\") == 238)  # Upper West Side North Zone Number\n",
    "    & (F.col(\"hvfhs_license_num\") == \"HV0003\")  # Uber's License Number\n",
    ").select(*EXTRACT_COLS).toPandas()\n",
    "\n",
    "# Extract predictions from Random Forest\n",
    "pred_sample_rf = predictions_rf.where(\n",
    "    (F.col(\"month\") == 4)\n",
    "    & (F.col(\"day\") == 15)\n",
    "    & (F.col(\"PULocationID\") == 238)  # Upper West Side North Zone Number\n",
    "    & (F.col(\"hvfhs_license_num\") == \"HV0003\")  # Uber's License Number\n",
    ").select(*EXTRACT_COLS).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Predictions vs Ground Truth (Pickups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "N = 24\n",
    "ind = np.arange(N)\n",
    "width = 0.25\n",
    "\n",
    "lm_vals = pred_sample_lm[\"prediction\"]\n",
    "bar1 = plt.bar(ind, lm_vals, width, color='r')\n",
    "\n",
    "rf_vals = pred_sample_rf[\"prediction\"]\n",
    "bar2 = plt.bar(ind+width, rf_vals, width, color='b')\n",
    "\n",
    "true_vals = pred_sample_lm[\"total_pickups\"]\n",
    "bar3 = plt.bar(ind+width*2, true_vals, width, color='g')\n",
    "\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel('Predicted Pickups')\n",
    "plt.title(\"True vs Predicted Demand\")\n",
    "\n",
    "plt.xticks(ind+width, [f\"{i:02}\" for i in range(0, 24)])\n",
    "plt.legend((bar1, bar2, bar3),\n",
    "           ('Prediction (OLS)', 'Prediction (Random Forest)', 'True Pickups'))\n",
    "plt.savefig(\"../plots/error_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Distribution of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract full prediction columns\n",
    "rf_dist = predictions_rf.select(\"prediction\").toPandas()\n",
    "lm_dist = predictions_lm.select(\"prediction\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density of Prediction (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "rf_dist.plot.density(legend=None)\n",
    "plt.title(\"Predictions by Random Forest\")\n",
    "plt.savefig(\"../plots/rf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density of Prediction (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "lm_dist.plot.density(legend=None)\n",
    "plt.title(\"Predictions by OLS\")\n",
    "plt.savefig(\"../plots/ols.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
