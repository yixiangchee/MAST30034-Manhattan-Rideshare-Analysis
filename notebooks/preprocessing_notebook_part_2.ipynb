{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAST30034 Applied Data Science Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preprocessing (II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1-1-2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.executor.memory\", \"10g\")\n",
    "    .config(\"spark.driver.memory\", \"10g\")\n",
    "    .config(\"spark.sql.session.timeZone\",  \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet(\"../data/curated/full_data/manhattan_data_cleaned\")\n",
    "sdf_test = spark.read.parquet(\"../data/curated/full_data/manhattan_data_test\")\n",
    "zones_rent = pd.read_csv(\"../data/curated/rent_taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Data For Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_PATH = \"../data/curated/analysis/\"\n",
    "if not os.path.exists(ANALYSIS_PATH):\n",
    "    os.makedirs(ANALYSIS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxi zone - monthly rent data\n",
    "zones = zones_rent[[\"LocationID\", \"Borough\", \"Zone\", \"service_zone\"]]\n",
    "RENT_COLS = [f\"2021-{i:02}\" for i in range(1, 13)]\n",
    "zones_rent[\"Average Median Rent\"] = zones_rent[RENT_COLS].mean(axis=1)\n",
    "zones_rent[\"Average Median Rent (Scaled)\"] = \\\n",
    "                        np.log(zones_rent[\"Average Median Rent\"])\n",
    "zones_rent.to_csv(\"../data/curated/analysis/zones_rent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly total pickups, each zone\n",
    "total_pu = sdf \\\n",
    "                .groupBy(F.month('pickup_datetime').alias(\"month\")) \\\n",
    "                .agg(\n",
    "                    F.count(\"PULocationID\").alias(\"total_pickups\")\n",
    "                ) \\\n",
    "                .orderBy(\"month\") \\\n",
    "                .toPandas()\n",
    "total_pu.to_csv(\"../data/curated/analysis/total_pu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly total pickups, each zone\n",
    "pu_by_hour = sdf \\\n",
    "                .groupBy(F.to_date('pickup_datetime').alias(\"date\"),\n",
    "                         F.hour('pickup_datetime').alias(\"hour\"),\n",
    "                         'PULocationID') \\\n",
    "                .agg(\n",
    "                    F.count(\"PULocationID\").alias(\"total_pickups\")\n",
    "                ) \\\n",
    "                .orderBy(\"date\", \"hour\", \"PULocationID\") \\\n",
    "                .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly pickup, each zone + its rent that month\n",
    "pu_rent = pu_by_hour \\\n",
    "        .merge(zones_rent, left_on=\"PULocationID\", right_on=\"LocationID\") \\\n",
    "        .drop([\"LocationID\", \"Unnamed: 0\", \"Borough\", \"service_zone\",\n",
    "               \"rental_zone\"], axis=1)\n",
    "\n",
    "# Extract rent of the month from columns\n",
    "pu_rent['month'] = pd.DatetimeIndex(pu_rent['date']).month\n",
    "pu_rent[\"rent\"] = pu_rent.apply(lambda row:\n",
    "                                row[f\"2021-{row['month']:02}\"], axis=1)\n",
    "pu_rent = pu_rent \\\n",
    "                .sort_values(by=[\"date\", \"hour\", 'PULocationID']) \\\n",
    "                .drop(RENT_COLS, axis=1)\n",
    "pu_rent.to_csv(\"../data/curated/analysis/pu_rent.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Data For Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly total pickups, each zone, for each rideshare company\n",
    "pu_by_hour_license = sdf \\\n",
    "                .groupBy(F.to_date('pickup_datetime').alias(\"date\"),\n",
    "                         F.hour('pickup_datetime').alias(\"hour\"),\n",
    "                         'PULocationID', \"hvfhs_license_num\") \\\n",
    "                .agg(\n",
    "                    F.count(\"PULocationID\").alias(\"total_pickups\")\n",
    "                ) \\\n",
    "                .orderBy(\"date\", \"hour\", \"PULocationID\", \"hvfhs_license_num\") \\\n",
    "                .toPandas()\n",
    "\n",
    "# Test data\n",
    "pu_by_hour_license_test = sdf_test \\\n",
    "                .groupBy(F.to_date('pickup_datetime').alias(\"date\"),\n",
    "                         F.hour('pickup_datetime').alias(\"hour\"),\n",
    "                         'PULocationID', \"hvfhs_license_num\") \\\n",
    "                .agg(\n",
    "                    F.count(\"PULocationID\").alias(\"total_pickups\")\n",
    "                ) \\\n",
    "                .orderBy(\"date\", \"hour\", \"PULocationID\", \"hvfhs_license_num\") \\\n",
    "                .toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Datetime and Rent Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_LIST = [\"month\", \"day\", \"day_of_week\", \"hour\",\n",
    "                    'PULocationID', \"hvfhs_license_num\"]\n",
    "\n",
    "# For training data\n",
    "pu_rent_train = pu_by_hour_license \\\n",
    "        .merge(zones_rent, left_on=\"PULocationID\", right_on=\"LocationID\") \\\n",
    "        .drop([\"LocationID\", \"Unnamed: 0\", \"Borough\", \"service_zone\",\n",
    "               \"rental_zone\", \"Average Median Rent\",\n",
    "               \"Average Median Rent (Scaled)\"], axis=1)\n",
    "\n",
    "pu_rent_train['month'] = pd.DatetimeIndex(pu_rent_train['date']).month\n",
    "pu_rent_train['day'] = pd.DatetimeIndex(pu_rent_train['date']).day\n",
    "pu_rent_train['day_of_week'] = pd \\\n",
    "        .DatetimeIndex(pu_rent_train['date']).dayofweek\n",
    "pu_rent_train[\"rent\"] = pu_rent_train \\\n",
    "        .apply(lambda row: row[f\"2021-{row['month']:02}\"], axis=1)\n",
    "pu_rent_train = pu_rent_train \\\n",
    "                .sort_values(by=CATEGORICAL_LIST) \\\n",
    "                .drop(RENT_COLS + [\"2022-04\", \"date\", \"Zone\"], axis=1)\n",
    "model_data = spark.createDataFrame(pu_rent_train)\n",
    "\n",
    "model_data \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet('../data/curated/modelling/model_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test data\n",
    "pu_rent_test = pu_by_hour_license_test \\\n",
    "        .merge(zones_rent, left_on=\"PULocationID\", right_on=\"LocationID\") \\\n",
    "        .drop([\"LocationID\", \"Unnamed: 0\", \"Borough\", \"service_zone\",\n",
    "               \"rental_zone\", \"Average Median Rent\",\n",
    "               \"Average Median Rent (Scaled)\"], axis=1)\n",
    "\n",
    "pu_rent_test['month'] = pd.DatetimeIndex(pu_rent_test['date']).month\n",
    "pu_rent_test['day'] = pd.DatetimeIndex(pu_rent_test['date']).day\n",
    "pu_rent_test['day_of_week'] = pd.DatetimeIndex(pu_rent_test['date']).dayofweek\n",
    "pu_rent_test[\"rent\"] = pu_rent_test[\"2022-04\"]\n",
    "pu_rent_test = pu_rent_test \\\n",
    "                .sort_values(by=CATEGORICAL_LIST) \\\n",
    "                .drop(RENT_COLS + [\"2022-04\", \"date\", \"Zone\"], axis=1)\n",
    "test_data = spark.createDataFrame(pu_rent_test)\n",
    "\n",
    "test_data \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet('../data/curated/modelling/model_test_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
